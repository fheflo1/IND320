{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "48071822",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "cwd = Path.cwd()\n",
    "root = cwd\n",
    "while root.name not in [\"src\"] and (root / \"src\").exists() is False:\n",
    "    if root.parent == root:\n",
    "        break\n",
    "    root = root.parent\n",
    "sys.path.append(str(root / \"src\"))\n",
    "\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "from pyspark.sql import SparkSession\n",
    "from api.elhub_api import fetch_elhub_data\n",
    "from cassandra.cluster import Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4577d8cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/11/14 10:26:06 WARN Utils: Your hostname, Fabians-MacBook-Pro.local resolves to a loopback address: 127.0.0.1; using 10.0.0.22 instead (on interface en0)\n",
      "25/11/14 10:26:06 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Ivy Default Cache set to: /Users/fabianheflo/.ivy2/cache\n",
      "The jars for the packages stored in: /Users/fabianheflo/.ivy2/jars\n",
      "com.datastax.spark#spark-cassandra-connector_2.12 added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-c5a64fdb-12ff-46c8-a715-8762b6a2e124;1.0\n",
      "\tconfs: [default]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/Users/fabianheflo/UNI_courses/IND320/IND320/.venv/lib/python3.12/site-packages/pyspark/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\tfound com.datastax.spark#spark-cassandra-connector_2.12;3.5.1 in central\n",
      "\tfound com.datastax.spark#spark-cassandra-connector-driver_2.12;3.5.1 in central\n",
      "\tfound org.scala-lang.modules#scala-collection-compat_2.12;2.11.0 in central\n",
      "\tfound org.apache.cassandra#java-driver-core-shaded;4.18.1 in central\n",
      "\tfound com.datastax.oss#native-protocol;1.5.1 in central\n",
      "\tfound com.datastax.oss#java-driver-shaded-guava;25.1-jre-graal-sub-1 in central\n",
      "\tfound com.typesafe#config;1.4.1 in central\n",
      "\tfound org.slf4j#slf4j-api;1.7.26 in central\n",
      "\tfound io.dropwizard.metrics#metrics-core;4.1.18 in central\n",
      "\tfound org.hdrhistogram#HdrHistogram;2.1.12 in central\n",
      "\tfound org.reactivestreams#reactive-streams;1.0.3 in central\n",
      "\tfound org.apache.cassandra#java-driver-mapper-runtime;4.18.1 in central\n",
      "\tfound org.apache.cassandra#java-driver-query-builder;4.18.1 in central\n",
      "\tfound org.apache.commons#commons-lang3;3.10 in central\n",
      "\tfound com.thoughtworks.paranamer#paranamer;2.8 in central\n",
      "\tfound org.scala-lang#scala-reflect;2.12.19 in central\n",
      ":: resolution report :: resolve 250ms :: artifacts dl 9ms\n",
      "\t:: modules in use:\n",
      "\tcom.datastax.oss#java-driver-shaded-guava;25.1-jre-graal-sub-1 from central in [default]\n",
      "\tcom.datastax.oss#native-protocol;1.5.1 from central in [default]\n",
      "\tcom.datastax.spark#spark-cassandra-connector-driver_2.12;3.5.1 from central in [default]\n",
      "\tcom.datastax.spark#spark-cassandra-connector_2.12;3.5.1 from central in [default]\n",
      "\tcom.thoughtworks.paranamer#paranamer;2.8 from central in [default]\n",
      "\tcom.typesafe#config;1.4.1 from central in [default]\n",
      "\tio.dropwizard.metrics#metrics-core;4.1.18 from central in [default]\n",
      "\torg.apache.cassandra#java-driver-core-shaded;4.18.1 from central in [default]\n",
      "\torg.apache.cassandra#java-driver-mapper-runtime;4.18.1 from central in [default]\n",
      "\torg.apache.cassandra#java-driver-query-builder;4.18.1 from central in [default]\n",
      "\torg.apache.commons#commons-lang3;3.10 from central in [default]\n",
      "\torg.hdrhistogram#HdrHistogram;2.1.12 from central in [default]\n",
      "\torg.reactivestreams#reactive-streams;1.0.3 from central in [default]\n",
      "\torg.scala-lang#scala-reflect;2.12.19 from central in [default]\n",
      "\torg.scala-lang.modules#scala-collection-compat_2.12;2.11.0 from central in [default]\n",
      "\torg.slf4j#slf4j-api;1.7.26 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   16  |   0   |   0   |   0   ||   16  |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-c5a64fdb-12ff-46c8-a715-8762b6a2e124\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 16 already retrieved (0kB/5ms)\n",
      "25/11/14 10:26:07 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… SparkSession started with Cassandra integration\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .appName(\"ElhubBronze\") \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .config(\"spark.jars.packages\", \"com.datastax.spark:spark-cassandra-connector_2.12:3.5.1\") \\\n",
    "    .config(\"spark.cassandra.connection.host\", \"127.0.0.1\") \\\n",
    "    .config(\"spark.cassandra.connection.port\", \"9042\") \\\n",
    "    .config(\"spark.sql.extensions\", \"com.datastax.spark.connector.CassandraSparkExtensions\") \\\n",
    "    .config(\"spark.sql.catalog.mycatalog\", \"com.datastax.spark.connector.datasource.CassandraCatalog\") \\\n",
    "    .config(\"spark.cassandra.output.consistency.level\", \"ONE\") \\\n",
    "    .config(\"spark.cassandra.connection.keepAliveMS\", \"60000\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "print(\"âœ… SparkSession started with Cassandra integration\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "50f1a12d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>endTime</th>\n",
       "      <th>lastUpdatedTime</th>\n",
       "      <th>priceArea</th>\n",
       "      <th>productionGroup</th>\n",
       "      <th>quantityKwh</th>\n",
       "      <th>startTime</th>\n",
       "      <th>meteringgridarea</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-01-01T01:00:00+01:00</td>\n",
       "      <td>2024-12-20T10:35:40+01:00</td>\n",
       "      <td>NO1</td>\n",
       "      <td>hydro</td>\n",
       "      <td>2507716.8</td>\n",
       "      <td>2021-01-01T00:00:00+01:00</td>\n",
       "      <td>NO1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-01-01T02:00:00+01:00</td>\n",
       "      <td>2024-12-20T10:35:40+01:00</td>\n",
       "      <td>NO1</td>\n",
       "      <td>hydro</td>\n",
       "      <td>2494728.0</td>\n",
       "      <td>2021-01-01T01:00:00+01:00</td>\n",
       "      <td>NO1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-01-01T03:00:00+01:00</td>\n",
       "      <td>2024-12-20T10:35:40+01:00</td>\n",
       "      <td>NO1</td>\n",
       "      <td>hydro</td>\n",
       "      <td>2486777.5</td>\n",
       "      <td>2021-01-01T02:00:00+01:00</td>\n",
       "      <td>NO1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-01-01T04:00:00+01:00</td>\n",
       "      <td>2024-12-20T10:35:40+01:00</td>\n",
       "      <td>NO1</td>\n",
       "      <td>hydro</td>\n",
       "      <td>2461176.0</td>\n",
       "      <td>2021-01-01T03:00:00+01:00</td>\n",
       "      <td>NO1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-01-01T05:00:00+01:00</td>\n",
       "      <td>2024-12-20T10:35:40+01:00</td>\n",
       "      <td>NO1</td>\n",
       "      <td>hydro</td>\n",
       "      <td>2466969.2</td>\n",
       "      <td>2021-01-01T04:00:00+01:00</td>\n",
       "      <td>NO1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     endTime            lastUpdatedTime priceArea  \\\n",
       "0  2021-01-01T01:00:00+01:00  2024-12-20T10:35:40+01:00       NO1   \n",
       "1  2021-01-01T02:00:00+01:00  2024-12-20T10:35:40+01:00       NO1   \n",
       "2  2021-01-01T03:00:00+01:00  2024-12-20T10:35:40+01:00       NO1   \n",
       "3  2021-01-01T04:00:00+01:00  2024-12-20T10:35:40+01:00       NO1   \n",
       "4  2021-01-01T05:00:00+01:00  2024-12-20T10:35:40+01:00       NO1   \n",
       "\n",
       "  productionGroup  quantityKwh                  startTime meteringgridarea  \n",
       "0           hydro    2507716.8  2021-01-01T00:00:00+01:00              NO1  \n",
       "1           hydro    2494728.0  2021-01-01T01:00:00+01:00              NO1  \n",
       "2           hydro    2486777.5  2021-01-01T02:00:00+01:00              NO1  \n",
       "3           hydro    2461176.0  2021-01-01T03:00:00+01:00              NO1  \n",
       "4           hydro    2466969.2  2021-01-01T04:00:00+01:00              NO1  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing API connection and data fetching\n",
    "start = datetime(2021, 1, 1)\n",
    "end = start + timedelta(days=1)\n",
    "df = fetch_elhub_data(start, end)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1bd4260a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… production_raw table created/verified.\n"
     ]
    }
   ],
   "source": [
    "# Connect to Cassandra\n",
    "cluster = Cluster(['127.0.0.1'])\n",
    "session = cluster.connect()\n",
    "\n",
    "session.execute(\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS elhub_data.production_raw (\n",
    "    pricearea TEXT,\n",
    "    productiongroup TEXT,\n",
    "    starttime TIMESTAMP,\n",
    "    endtime TIMESTAMP,\n",
    "    quantitykwh DOUBLE,\n",
    "    PRIMARY KEY ((pricearea), productiongroup, starttime)\n",
    ");\n",
    "\"\"\")\n",
    "\n",
    "print(\"âœ… production_raw table created/verified.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "13890d67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ§¹ Cleared existing data from production_raw\n"
     ]
    }
   ],
   "source": [
    "# Delete existing data for clean slate (for testing)\n",
    "session.execute(\"TRUNCATE elhub_data.production_raw\")\n",
    "print(\"ðŸ§¹ Cleared existing data from production_raw\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c350c0f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1: 2021-01-01 â†’ 2021-01-08\n",
      "  Saved 4032 rows.\n",
      "Batch 2: 2021-01-08 â†’ 2021-01-15\n",
      "  Saved 4032 rows.\n",
      "Batch 3: 2021-01-15 â†’ 2021-01-22\n",
      "  Saved 4032 rows.\n",
      "Batch 4: 2021-01-22 â†’ 2021-01-29\n",
      "  Saved 4032 rows.\n",
      "Batch 5: 2021-01-29 â†’ 2021-02-05\n",
      "  Saved 4032 rows.\n",
      "Batch 6: 2021-02-05 â†’ 2021-02-12\n",
      "  Saved 4032 rows.\n",
      "Batch 7: 2021-02-12 â†’ 2021-02-19\n",
      "  Saved 4032 rows.\n",
      "Batch 8: 2021-02-19 â†’ 2021-02-26\n",
      "  Saved 4032 rows.\n",
      "Batch 9: 2021-02-26 â†’ 2021-03-05\n",
      "  Saved 4032 rows.\n",
      "Batch 10: 2021-03-05 â†’ 2021-03-12\n",
      "  Saved 4032 rows.\n",
      "Batch 11: 2021-03-12 â†’ 2021-03-19\n",
      "  Saved 4032 rows.\n",
      "Batch 12: 2021-03-19 â†’ 2021-03-26\n",
      "  Saved 4032 rows.\n",
      "Batch 13: 2021-03-26 â†’ 2021-04-02\n",
      "  Saved 4008 rows.\n",
      "Batch 14: 2021-04-02 â†’ 2021-04-09\n",
      "  Saved 4032 rows.\n",
      "Batch 15: 2021-04-09 â†’ 2021-04-16\n",
      "  Saved 4032 rows.\n",
      "Batch 16: 2021-04-16 â†’ 2021-04-23\n",
      "  Saved 4032 rows.\n",
      "Batch 17: 2021-04-23 â†’ 2021-04-30\n",
      "  Saved 4032 rows.\n",
      "Batch 18: 2021-04-30 â†’ 2021-05-07\n",
      "  Saved 4032 rows.\n",
      "Batch 19: 2021-05-07 â†’ 2021-05-14\n",
      "  Saved 4032 rows.\n",
      "Batch 20: 2021-05-14 â†’ 2021-05-21\n",
      "  Saved 4032 rows.\n",
      "Batch 21: 2021-05-21 â†’ 2021-05-28\n",
      "  Saved 4032 rows.\n",
      "Batch 22: 2021-05-28 â†’ 2021-06-04\n",
      "  Saved 4080 rows.\n",
      "Batch 23: 2021-06-04 â†’ 2021-06-11\n",
      "  Saved 4200 rows.\n",
      "Batch 24: 2021-06-11 â†’ 2021-06-18\n",
      "  Saved 4200 rows.\n",
      "Batch 25: 2021-06-18 â†’ 2021-06-25\n",
      "  Saved 4200 rows.\n",
      "Batch 26: 2021-06-25 â†’ 2021-07-02\n",
      "  Saved 4200 rows.\n",
      "Batch 27: 2021-07-02 â†’ 2021-07-09\n",
      "  Saved 4200 rows.\n",
      "Batch 28: 2021-07-09 â†’ 2021-07-16\n",
      "  Saved 4200 rows.\n",
      "Batch 29: 2021-07-16 â†’ 2021-07-23\n",
      "  Saved 4200 rows.\n",
      "Batch 30: 2021-07-23 â†’ 2021-07-30\n",
      "  Saved 4200 rows.\n",
      "Batch 31: 2021-07-30 â†’ 2021-08-06\n",
      "  Saved 4200 rows.\n",
      "Batch 32: 2021-08-06 â†’ 2021-08-13\n",
      "  Saved 4200 rows.\n",
      "Batch 33: 2021-08-13 â†’ 2021-08-20\n",
      "  Saved 4200 rows.\n",
      "Batch 34: 2021-08-20 â†’ 2021-08-27\n",
      "  Saved 4200 rows.\n",
      "Batch 35: 2021-08-27 â†’ 2021-09-03\n",
      "  Saved 4200 rows.\n",
      "Batch 36: 2021-09-03 â†’ 2021-09-10\n",
      "  Saved 4200 rows.\n",
      "Batch 37: 2021-09-10 â†’ 2021-09-17\n",
      "  Saved 4200 rows.\n",
      "Batch 38: 2021-09-17 â†’ 2021-09-24\n",
      "  Saved 4200 rows.\n",
      "Batch 39: 2021-09-24 â†’ 2021-10-01\n",
      "  Saved 4200 rows.\n",
      "Batch 40: 2021-10-01 â†’ 2021-10-08\n",
      "  Saved 4200 rows.\n",
      "Batch 41: 2021-10-08 â†’ 2021-10-15\n",
      "  Saved 4200 rows.\n",
      "Batch 42: 2021-10-15 â†’ 2021-10-22\n",
      "  Saved 4200 rows.\n",
      "Batch 43: 2021-10-22 â†’ 2021-10-29\n",
      "  Saved 4200 rows.\n",
      "Batch 44: 2021-10-29 â†’ 2021-11-05\n",
      "  Saved 4225 rows.\n",
      "Batch 45: 2021-11-05 â†’ 2021-11-12\n",
      "  Saved 4200 rows.\n",
      "Batch 46: 2021-11-12 â†’ 2021-11-19\n",
      "  Saved 4200 rows.\n",
      "Batch 47: 2021-11-19 â†’ 2021-11-26\n",
      "  Saved 4200 rows.\n",
      "Batch 48: 2021-11-26 â†’ 2021-12-03\n",
      "  Saved 4200 rows.\n",
      "Batch 49: 2021-12-03 â†’ 2021-12-10\n",
      "  Saved 4200 rows.\n",
      "Batch 50: 2021-12-10 â†’ 2021-12-17\n",
      "  Saved 4200 rows.\n",
      "Batch 51: 2021-12-17 â†’ 2021-12-24\n",
      "  Saved 4200 rows.\n",
      "Batch 52: 2021-12-24 â†’ 2021-12-31\n",
      "  Saved 4200 rows.\n",
      "Batch 1: 2022-01-01 â†’ 2022-01-08\n",
      "  Saved 4200 rows.\n",
      "Batch 2: 2022-01-08 â†’ 2022-01-15\n",
      "  Saved 4200 rows.\n",
      "Batch 3: 2022-01-15 â†’ 2022-01-22\n",
      "  Saved 4200 rows.\n",
      "Batch 4: 2022-01-22 â†’ 2022-01-29\n",
      "  Saved 4200 rows.\n",
      "Batch 5: 2022-01-29 â†’ 2022-02-05\n",
      "  Saved 4200 rows.\n",
      "Batch 6: 2022-02-05 â†’ 2022-02-12\n",
      "  Saved 4200 rows.\n",
      "Batch 7: 2022-02-12 â†’ 2022-02-19\n",
      "  Saved 4200 rows.\n",
      "Batch 8: 2022-02-19 â†’ 2022-02-26\n",
      "  Saved 4200 rows.\n",
      "Batch 9: 2022-02-26 â†’ 2022-03-05\n",
      "  Saved 4200 rows.\n",
      "Batch 10: 2022-03-05 â†’ 2022-03-12\n",
      "  Saved 4200 rows.\n",
      "Batch 11: 2022-03-12 â†’ 2022-03-19\n",
      "  Saved 4200 rows.\n",
      "Batch 12: 2022-03-19 â†’ 2022-03-26\n",
      "  Saved 4200 rows.\n",
      "Batch 13: 2022-03-26 â†’ 2022-04-02\n",
      "  Saved 4175 rows.\n",
      "Batch 14: 2022-04-02 â†’ 2022-04-09\n",
      "  Saved 4200 rows.\n",
      "Batch 15: 2022-04-09 â†’ 2022-04-16\n",
      "  Saved 4200 rows.\n",
      "Batch 16: 2022-04-16 â†’ 2022-04-23\n",
      "  Saved 4200 rows.\n",
      "Batch 17: 2022-04-23 â†’ 2022-04-30\n",
      "  Saved 4200 rows.\n",
      "Batch 18: 2022-04-30 â†’ 2022-05-07\n",
      "  Saved 4200 rows.\n",
      "Batch 19: 2022-05-07 â†’ 2022-05-14\n",
      "  Saved 4200 rows.\n",
      "Batch 20: 2022-05-14 â†’ 2022-05-21\n",
      "  Saved 4200 rows.\n",
      "Batch 21: 2022-05-21 â†’ 2022-05-28\n",
      "  Saved 4200 rows.\n",
      "Batch 22: 2022-05-28 â†’ 2022-06-04\n",
      "  Saved 4200 rows.\n",
      "Batch 23: 2022-06-04 â†’ 2022-06-11\n",
      "  Saved 4200 rows.\n",
      "Batch 24: 2022-06-11 â†’ 2022-06-18\n",
      "  Saved 4200 rows.\n",
      "Batch 25: 2022-06-18 â†’ 2022-06-25\n",
      "  Saved 4200 rows.\n",
      "Batch 26: 2022-06-25 â†’ 2022-07-02\n",
      "  Saved 4200 rows.\n",
      "Batch 27: 2022-07-02 â†’ 2022-07-09\n",
      "  Saved 4200 rows.\n",
      "Batch 28: 2022-07-09 â†’ 2022-07-16\n",
      "  Saved 4200 rows.\n",
      "Batch 29: 2022-07-16 â†’ 2022-07-23\n",
      "  Saved 4200 rows.\n",
      "Batch 30: 2022-07-23 â†’ 2022-07-30\n",
      "  Saved 4200 rows.\n",
      "Batch 31: 2022-07-30 â†’ 2022-08-06\n",
      "  Saved 4200 rows.\n",
      "Batch 32: 2022-08-06 â†’ 2022-08-13\n",
      "  Saved 4200 rows.\n",
      "Batch 33: 2022-08-13 â†’ 2022-08-20\n",
      "  Saved 4200 rows.\n",
      "Batch 34: 2022-08-20 â†’ 2022-08-27\n",
      "  Saved 4200 rows.\n",
      "Batch 35: 2022-08-27 â†’ 2022-09-03\n",
      "  Saved 4200 rows.\n",
      "Batch 36: 2022-09-03 â†’ 2022-09-10\n",
      "  Saved 4200 rows.\n",
      "Batch 37: 2022-09-10 â†’ 2022-09-17\n",
      "  Saved 4200 rows.\n",
      "Batch 38: 2022-09-17 â†’ 2022-09-24\n",
      "  Saved 4200 rows.\n",
      "Batch 39: 2022-09-24 â†’ 2022-10-01\n",
      "  Saved 4200 rows.\n",
      "Batch 40: 2022-10-01 â†’ 2022-10-08\n",
      "  Saved 4200 rows.\n",
      "Batch 41: 2022-10-08 â†’ 2022-10-15\n",
      "  Saved 4200 rows.\n",
      "Batch 42: 2022-10-15 â†’ 2022-10-22\n",
      "  Saved 4200 rows.\n",
      "Batch 43: 2022-10-22 â†’ 2022-10-29\n",
      "  Saved 4200 rows.\n",
      "Batch 44: 2022-10-29 â†’ 2022-11-05\n",
      "  Saved 4225 rows.\n",
      "Batch 45: 2022-11-05 â†’ 2022-11-12\n",
      "  Saved 4200 rows.\n",
      "Batch 46: 2022-11-12 â†’ 2022-11-19\n",
      "  Saved 4200 rows.\n",
      "Batch 47: 2022-11-19 â†’ 2022-11-26\n",
      "  Saved 4200 rows.\n",
      "Batch 48: 2022-11-26 â†’ 2022-12-03\n",
      "  Saved 4200 rows.\n",
      "Batch 49: 2022-12-03 â†’ 2022-12-10\n",
      "  Saved 4200 rows.\n",
      "Batch 50: 2022-12-10 â†’ 2022-12-17\n",
      "  Saved 4200 rows.\n",
      "Batch 51: 2022-12-17 â†’ 2022-12-24\n",
      "  Saved 4200 rows.\n",
      "Batch 52: 2022-12-24 â†’ 2022-12-31\n",
      "  Saved 4200 rows.\n",
      "Batch 1: 2023-01-01 â†’ 2023-01-08\n",
      "  Saved 4200 rows.\n",
      "Batch 2: 2023-01-08 â†’ 2023-01-15\n",
      "  Saved 4200 rows.\n",
      "Batch 3: 2023-01-15 â†’ 2023-01-22\n",
      "  Saved 4200 rows.\n",
      "Batch 4: 2023-01-22 â†’ 2023-01-29\n",
      "  Saved 4200 rows.\n",
      "Batch 5: 2023-01-29 â†’ 2023-02-05\n",
      "  Saved 4200 rows.\n",
      "Batch 6: 2023-02-05 â†’ 2023-02-12\n",
      "  Saved 4200 rows.\n",
      "Batch 7: 2023-02-12 â†’ 2023-02-19\n",
      "  Saved 4200 rows.\n",
      "Batch 8: 2023-02-19 â†’ 2023-02-26\n",
      "  Saved 4200 rows.\n",
      "Batch 9: 2023-02-26 â†’ 2023-03-05\n",
      "  Saved 4200 rows.\n",
      "Batch 10: 2023-03-05 â†’ 2023-03-12\n",
      "  Saved 4200 rows.\n",
      "Batch 11: 2023-03-12 â†’ 2023-03-19\n",
      "  Saved 4200 rows.\n",
      "Batch 12: 2023-03-19 â†’ 2023-03-26\n",
      "  Saved 4200 rows.\n",
      "Batch 13: 2023-03-26 â†’ 2023-04-02\n",
      "  Saved 4175 rows.\n",
      "Batch 14: 2023-04-02 â†’ 2023-04-09\n",
      "  Saved 4200 rows.\n",
      "Batch 15: 2023-04-09 â†’ 2023-04-16\n",
      "  Saved 4200 rows.\n",
      "Batch 16: 2023-04-16 â†’ 2023-04-23\n",
      "  Saved 4200 rows.\n",
      "Batch 17: 2023-04-23 â†’ 2023-04-30\n",
      "  Saved 4200 rows.\n",
      "Batch 18: 2023-04-30 â†’ 2023-05-07\n",
      "  Saved 4200 rows.\n",
      "Batch 19: 2023-05-07 â†’ 2023-05-14\n",
      "  Saved 4200 rows.\n",
      "Batch 20: 2023-05-14 â†’ 2023-05-21\n",
      "  Saved 4200 rows.\n",
      "Batch 21: 2023-05-21 â†’ 2023-05-28\n",
      "  Saved 4200 rows.\n",
      "Batch 22: 2023-05-28 â†’ 2023-06-04\n",
      "  Saved 4200 rows.\n",
      "Batch 23: 2023-06-04 â†’ 2023-06-11\n",
      "  Saved 4200 rows.\n",
      "Batch 24: 2023-06-11 â†’ 2023-06-18\n",
      "  Saved 4200 rows.\n",
      "Batch 25: 2023-06-18 â†’ 2023-06-25\n",
      "  Saved 4200 rows.\n",
      "Batch 26: 2023-06-25 â†’ 2023-07-02\n",
      "  Saved 4200 rows.\n",
      "Batch 27: 2023-07-02 â†’ 2023-07-09\n",
      "  Saved 4200 rows.\n",
      "Batch 28: 2023-07-09 â†’ 2023-07-16\n",
      "  Saved 4200 rows.\n",
      "Batch 29: 2023-07-16 â†’ 2023-07-23\n",
      "  Saved 4200 rows.\n",
      "Batch 30: 2023-07-23 â†’ 2023-07-30\n",
      "  Saved 4200 rows.\n",
      "Batch 31: 2023-07-30 â†’ 2023-08-06\n",
      "  Saved 4200 rows.\n",
      "Batch 32: 2023-08-06 â†’ 2023-08-13\n",
      "  Saved 4200 rows.\n",
      "Batch 33: 2023-08-13 â†’ 2023-08-20\n",
      "  Saved 4200 rows.\n",
      "Batch 34: 2023-08-20 â†’ 2023-08-27\n",
      "  Saved 4200 rows.\n",
      "Batch 35: 2023-08-27 â†’ 2023-09-03\n",
      "  Saved 4200 rows.\n",
      "Batch 36: 2023-09-03 â†’ 2023-09-10\n",
      "  Saved 4200 rows.\n",
      "Batch 37: 2023-09-10 â†’ 2023-09-17\n",
      "  Saved 4200 rows.\n",
      "Batch 38: 2023-09-17 â†’ 2023-09-24\n",
      "  Saved 4200 rows.\n",
      "Batch 39: 2023-09-24 â†’ 2023-10-01\n",
      "  Saved 4200 rows.\n",
      "Batch 40: 2023-10-01 â†’ 2023-10-08\n",
      "  Saved 4200 rows.\n",
      "Batch 41: 2023-10-08 â†’ 2023-10-15\n",
      "  Saved 4200 rows.\n",
      "Batch 42: 2023-10-15 â†’ 2023-10-22\n",
      "  Saved 4200 rows.\n",
      "Batch 43: 2023-10-22 â†’ 2023-10-29\n",
      "  Saved 4200 rows.\n",
      "Batch 44: 2023-10-29 â†’ 2023-11-05\n",
      "  Saved 4225 rows.\n",
      "Batch 45: 2023-11-05 â†’ 2023-11-12\n",
      "  Saved 4200 rows.\n",
      "Batch 46: 2023-11-12 â†’ 2023-11-19\n",
      "  Saved 4200 rows.\n",
      "Batch 47: 2023-11-19 â†’ 2023-11-26\n",
      "  Saved 4200 rows.\n",
      "Batch 48: 2023-11-26 â†’ 2023-12-03\n",
      "  Saved 4200 rows.\n",
      "Batch 49: 2023-12-03 â†’ 2023-12-10\n",
      "  Saved 4200 rows.\n",
      "Batch 50: 2023-12-10 â†’ 2023-12-17\n",
      "  Saved 4200 rows.\n",
      "Batch 51: 2023-12-17 â†’ 2023-12-24\n",
      "  Saved 4200 rows.\n",
      "Batch 52: 2023-12-24 â†’ 2023-12-31\n",
      "  Saved 4200 rows.\n",
      "Batch 1: 2024-01-01 â†’ 2024-01-08\n",
      "  Saved 4200 rows.\n",
      "Batch 2: 2024-01-08 â†’ 2024-01-15\n",
      "  Saved 4200 rows.\n",
      "Batch 3: 2024-01-15 â†’ 2024-01-22\n",
      "  Saved 4200 rows.\n",
      "Batch 4: 2024-01-22 â†’ 2024-01-29\n",
      "  Saved 4200 rows.\n",
      "Batch 5: 2024-01-29 â†’ 2024-02-05\n",
      "  Saved 4200 rows.\n",
      "Batch 6: 2024-02-05 â†’ 2024-02-12\n",
      "  Saved 4200 rows.\n",
      "Batch 7: 2024-02-12 â†’ 2024-02-19\n",
      "  Saved 4200 rows.\n",
      "Batch 8: 2024-02-19 â†’ 2024-02-26\n",
      "  Saved 4200 rows.\n",
      "Batch 9: 2024-02-26 â†’ 2024-03-04\n",
      "  Saved 4200 rows.\n",
      "Batch 10: 2024-03-04 â†’ 2024-03-11\n",
      "  Saved 4200 rows.\n",
      "Batch 11: 2024-03-11 â†’ 2024-03-18\n",
      "  Saved 4200 rows.\n",
      "Batch 12: 2024-03-18 â†’ 2024-03-25\n",
      "  Saved 4200 rows.\n",
      "Batch 13: 2024-03-25 â†’ 2024-04-01\n",
      "  Saved 4175 rows.\n",
      "Batch 14: 2024-04-01 â†’ 2024-04-08\n",
      "  Saved 4200 rows.\n",
      "Batch 15: 2024-04-08 â†’ 2024-04-15\n",
      "  Saved 4200 rows.\n",
      "Batch 16: 2024-04-15 â†’ 2024-04-22\n",
      "  Saved 4200 rows.\n",
      "Batch 17: 2024-04-22 â†’ 2024-04-29\n",
      "  Saved 4200 rows.\n",
      "Batch 18: 2024-04-29 â†’ 2024-05-06\n",
      "  Saved 4200 rows.\n",
      "Batch 19: 2024-05-06 â†’ 2024-05-13\n",
      "  Saved 4200 rows.\n",
      "Batch 20: 2024-05-13 â†’ 2024-05-20\n",
      "  Saved 4200 rows.\n",
      "Batch 21: 2024-05-20 â†’ 2024-05-27\n",
      "  Saved 4200 rows.\n",
      "Batch 22: 2024-05-27 â†’ 2024-06-03\n",
      "  Saved 4200 rows.\n",
      "Batch 23: 2024-06-03 â†’ 2024-06-10\n",
      "  Saved 4200 rows.\n",
      "Batch 24: 2024-06-10 â†’ 2024-06-17\n",
      "  Saved 4200 rows.\n",
      "Batch 25: 2024-06-17 â†’ 2024-06-24\n",
      "  Saved 4200 rows.\n",
      "Batch 26: 2024-06-24 â†’ 2024-07-01\n",
      "  Saved 4200 rows.\n",
      "Batch 27: 2024-07-01 â†’ 2024-07-08\n",
      "  Saved 4200 rows.\n",
      "Batch 28: 2024-07-08 â†’ 2024-07-15\n",
      "  Saved 4200 rows.\n",
      "Batch 29: 2024-07-15 â†’ 2024-07-22\n",
      "  Saved 4200 rows.\n",
      "Batch 30: 2024-07-22 â†’ 2024-07-29\n",
      "  Saved 4200 rows.\n",
      "Batch 31: 2024-07-29 â†’ 2024-08-05\n",
      "  Saved 4200 rows.\n",
      "Batch 32: 2024-08-05 â†’ 2024-08-12\n",
      "  Saved 4200 rows.\n",
      "Batch 33: 2024-08-12 â†’ 2024-08-19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Saved 4200 rows.\n",
      "Batch 34: 2024-08-19 â†’ 2024-08-26\n",
      "  Saved 4200 rows.\n",
      "Batch 35: 2024-08-26 â†’ 2024-09-02\n",
      "  Saved 4200 rows.\n",
      "Batch 36: 2024-09-02 â†’ 2024-09-09\n",
      "  Saved 4200 rows.\n",
      "Batch 37: 2024-09-09 â†’ 2024-09-16\n",
      "  Saved 4200 rows.\n",
      "Batch 38: 2024-09-16 â†’ 2024-09-23\n",
      "  Saved 4200 rows.\n",
      "Batch 39: 2024-09-23 â†’ 2024-09-30\n",
      "  Saved 4200 rows.\n",
      "Batch 40: 2024-09-30 â†’ 2024-10-07\n",
      "  Saved 4200 rows.\n",
      "Batch 41: 2024-10-07 â†’ 2024-10-14\n",
      "  Saved 4200 rows.\n",
      "Batch 42: 2024-10-14 â†’ 2024-10-21\n",
      "  Saved 4200 rows.\n",
      "Batch 43: 2024-10-21 â†’ 2024-10-28\n",
      "  Saved 4225 rows.\n",
      "Batch 44: 2024-10-28 â†’ 2024-11-04\n",
      "  Saved 4200 rows.\n",
      "Batch 45: 2024-11-04 â†’ 2024-11-11\n",
      "  Saved 4200 rows.\n",
      "Batch 46: 2024-11-11 â†’ 2024-11-18\n",
      "  Saved 4200 rows.\n",
      "Batch 47: 2024-11-18 â†’ 2024-11-25\n",
      "  Saved 4200 rows.\n",
      "Batch 48: 2024-11-25 â†’ 2024-12-02\n",
      "  Saved 4200 rows.\n",
      "Batch 49: 2024-12-02 â†’ 2024-12-09\n",
      "  Saved 4200 rows.\n",
      "Batch 50: 2024-12-09 â†’ 2024-12-16\n",
      "  Saved 4200 rows.\n",
      "Batch 51: 2024-12-16 â†’ 2024-12-23\n",
      "  Saved 4200 rows.\n",
      "Batch 52: 2024-12-23 â†’ 2024-12-30\n",
      "  Saved 4200 rows.\n",
      "Batch 53: 2024-12-30 â†’ 2025-01-01\n",
      "  Saved 1200 rows.\n"
     ]
    }
   ],
   "source": [
    "years = [2021, 2022, 2023, 2024]\n",
    "price_areas = [\"NO1\",\"NO2\",\"NO3\",\"NO4\",\"NO5\"]\n",
    "\n",
    "for year in years:\n",
    "\n",
    "    start_date = datetime(year, 1, 1)\n",
    "    end_date   = datetime(year, 12, 31)\n",
    "\n",
    "    current = start_date\n",
    "    batch = 1\n",
    "\n",
    "    while current < end_date:\n",
    "\n",
    "        next_batch = current + timedelta(days=7)\n",
    "\n",
    "        # Last batch: stop exactly at end_date + 1 day\n",
    "        if next_batch > end_date:\n",
    "            next_batch = end_date + timedelta(days=1)\n",
    "\n",
    "        print(f\"Batch {batch}: {current.date()} â†’ {next_batch.date()}\")\n",
    "\n",
    "        df = fetch_elhub_data(current, next_batch)\n",
    "\n",
    "        if not df.empty:\n",
    "            df.columns = [c.lower() for c in df.columns]\n",
    "            sdf = spark.createDataFrame(df)\n",
    "\n",
    "            sdf.write \\\n",
    "                .format(\"org.apache.spark.sql.cassandra\") \\\n",
    "                .mode(\"append\") \\\n",
    "                .options(table=\"production_raw\", keyspace=\"elhub_data\") \\\n",
    "                .save()\n",
    "\n",
    "            print(f\"  Saved {len(df)} rows.\")\n",
    "        else:\n",
    "            print(\"  No data.\")\n",
    "\n",
    "        current = next_batch\n",
    "        batch += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b2ecdee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Data written to Cassandra (bronze layer)\n"
     ]
    }
   ],
   "source": [
    "df.columns  = [c.lower() for c in df.columns]  # Cassandra likes lowercase column names\n",
    "sdf = spark.createDataFrame(df)\n",
    "sdf.write \\\n",
    "    .format(\"org.apache.spark.sql.cassandra\") \\\n",
    "    .mode(\"append\") \\\n",
    "    .options(table=\"production_raw\", keyspace=\"elhub_data\") \\\n",
    "    .save()\n",
    "\n",
    "print(\"âœ… Data written to Cassandra (bronze layer)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6da860d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[pricearea: string, starttime: timestamp, productiongroup: string, endtime: timestamp, lastupdatedtime: timestamp, meteringgridarea: string, quantitykwh: double]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.read \\\n",
    "    .format(\"org.apache.spark.sql.cassandra\") \\\n",
    "    .option(\"table\", \"production_raw\") \\\n",
    "    .option(\"keyspace\", \"elhub_data\") \\\n",
    "    .load()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
